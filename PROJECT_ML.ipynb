{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd615ff-608b-46e2-802f-a611ef0f0360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert_masks.py\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "# Input folder: RGB masks\n",
    "input_mask_dir = \"DeepGlobe/train\"\n",
    "\n",
    "# Output folder: class-index masks\n",
    "output_mask_dir = \"DeepGlobe/train_converted\"\n",
    "os.makedirs(output_mask_dir, exist_ok=True)\n",
    "\n",
    "# RGB to class index mapping\n",
    "rgb_to_class = {\n",
    "    (0, 255, 255): 0,       # Urban\n",
    "    (255, 255, 0): 1,       # Agriculture\n",
    "    (255, 0, 255): 2,       # Rangeland\n",
    "    (0, 255, 0): 3,         # Forest\n",
    "    (0, 0, 255): 4,         # Water\n",
    "    (255, 255, 255): 5,     # Barren\n",
    "    (0, 0, 0): 6            # Unknown\n",
    "}\n",
    "\n",
    "# Gather mask filenames\n",
    "mask_files = [f for f in os.listdir(input_mask_dir) if f.endswith((\"_mask.jpeg\", \"_mask.png\"))]\n",
    "\n",
    "# Convert masks with progress bar\n",
    "for filename in tqdm(mask_files, desc=\"ðŸ”„ Converting masks\"):\n",
    "    mask_path = os.path.join(input_mask_dir, filename)\n",
    "    rgb_mask = np.array(Image.open(mask_path).convert(\"RGB\"))\n",
    "\n",
    "    class_mask = np.zeros(rgb_mask.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    for rgb, class_idx in rgb_to_class.items():\n",
    "        match = np.all(rgb_mask == rgb, axis=-1)\n",
    "        class_mask[match] = class_idx\n",
    "\n",
    "    output_file = filename.replace(\"_mask\", \"_mask_class\").replace(\".jpeg\", \".png\")\n",
    "    output_path = os.path.join(output_mask_dir, output_file)\n",
    "    Image.fromarray(class_mask).save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737ca853-7005-4759-985e-0710d1c5cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing.py\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Tile size & stride\n",
    "TILE_SIZE = 256\n",
    "STRIDE = 256\n",
    "\n",
    "# Input folders\n",
    "IMAGE_DIR = \"DeepGlobe/temp\"\n",
    "LABEL_DIR = \"DeepGlobe/temp_converted\"\n",
    "\n",
    "# Output folders\n",
    "TILE_IMG_DIR = \"data/tiles/images\"\n",
    "TILE_LABEL_DIR = \"data/tiles/labels\"\n",
    "\n",
    "def create_required_directories():\n",
    "    os.makedirs(TILE_IMG_DIR, exist_ok=True)\n",
    "    os.makedirs(TILE_LABEL_DIR, exist_ok=True)\n",
    "\n",
    "def tile_image_and_mask(image_path, mask_path, tile_size=TILE_SIZE, stride=STRIDE):\n",
    "    image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
    "    mask = np.array(Image.open(mask_path))\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    tile_id = 0\n",
    "    img_name = os.path.basename(image_path).split('_')[0]\n",
    "\n",
    "    for y in range(0, h - tile_size + 1, stride):\n",
    "        for x in range(0, w - tile_size + 1, stride):\n",
    "            img_tile = image[y:y + tile_size, x:x + tile_size]\n",
    "            mask_tile = mask[y:y + tile_size, x:x + tile_size]\n",
    "\n",
    "            img_tile_path = os.path.join(TILE_IMG_DIR, f\"{img_name}_tile_{tile_id}.png\")\n",
    "            mask_tile_path = os.path.join(TILE_LABEL_DIR, f\"{img_name}_tile_{tile_id}.png\")\n",
    "\n",
    "            Image.fromarray(img_tile).save(img_tile_path)\n",
    "            Image.fromarray(mask_tile).save(mask_tile_path)\n",
    "            tile_id += 1\n",
    "\n",
    "    print(f\"âœ… Tiled {img_name}: {tile_id} patches\")\n",
    "\n",
    "def batch_tile_dataset():\n",
    "    create_required_directories()\n",
    "    all_files = sorted(os.listdir(IMAGE_DIR))\n",
    "    sat_images = [f for f in all_files if f.endswith('_sat.jpg')]\n",
    "\n",
    "    print(\"ðŸ§¾ Found satellite images:\", len(sat_images))\n",
    "\n",
    "    for sat_file in sat_images:\n",
    "        base_name = sat_file.replace('_sat.jpg', '')  \n",
    "        mask_file = f\"{base_name}_mask_class.png\"\n",
    "        sat_path = os.path.join(IMAGE_DIR, sat_file)\n",
    "        mask_path = os.path.join(LABEL_DIR, mask_file)\n",
    "\n",
    "        print(f\"ðŸ”„ Processing: {sat_file}\")\n",
    "\n",
    "        if os.path.exists(mask_path):\n",
    "            tile_image_and_mask(sat_path, mask_path)\n",
    "        else:\n",
    "            print(f\"âš ï¸ Mask missing for {sat_file}\")\n",
    "if __name__ == \"__main__\":\n",
    "    batch_tile_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f741c9f-f5cf-4c95-9255-559d96d75bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp_classifier_task1.py\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import joblib\n",
    "\n",
    "# Tile folders\n",
    "TILE_IMG_DIR = \"data/tiles/images\"\n",
    "TILE_LABEL_DIR = \"data/tiles/labels\"\n",
    "\n",
    "# Collect file names\n",
    "tile_files = sorted(os.listdir(TILE_IMG_DIR))\n",
    "print(f\" Found {len(tile_files)} tiles\")\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "def extract_features(image_path):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img = np.array(img)\n",
    "    r, g, b = img[:, :, 0].mean(), img[:, :, 1].mean(), img[:, :, 2].mean()\n",
    "    return [r, g, b]\n",
    "\n",
    "def extract_label(mask_path):\n",
    "    mask = np.array(Image.open(mask_path))\n",
    "    flat = mask.flatten()\n",
    "    flat = flat[flat > 0]  # ignore class 0 (background)\n",
    "    if len(flat) == 0:\n",
    "        return 0\n",
    "    return int(np.bincount(flat).argmax())\n",
    "\n",
    "# Load features and labels\n",
    "for tile in tqdm(tile_files, desc=\" Loading tiles\"):\n",
    "    img_path = os.path.join(TILE_IMG_DIR, tile)\n",
    "    mask_path = os.path.join(TILE_LABEL_DIR, tile)\n",
    "\n",
    "    if os.path.exists(mask_path):\n",
    "        features = extract_features(img_path)\n",
    "        label = extract_label(mask_path)\n",
    "\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"\\nâœ… Dataset shape: {X.shape}, Labels: {Counter(y)}\")\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train MLP\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30, 15, 20), max_iter=500, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(f\"\\nâœ… MLP Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nðŸ“Š Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save model\n",
    "joblib.dump(mlp, \"mlp_landcover_model.pkl\")\n",
    "print(\"âœ… MLP model saved as mlp_landcover_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89bc782-8213-4ddd-980e-c344bdcc435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble_classifier_task2.py\n",
    "mport os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "IMAGE_DIR = \"data/tiles/images\"\n",
    "LABEL_DIR = \"data/tiles/labels\"\n",
    "\n",
    "def extract_features(image_path):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img = np.array(img)\n",
    "    r_mean = img[:, :, 0].mean()\n",
    "    g_mean = img[:, :, 1].mean()\n",
    "    b_mean = img[:, :, 2].mean()\n",
    "    return [r_mean, g_mean, b_mean]\n",
    "\n",
    "def extract_label(mask_path):\n",
    "    mask = Image.open(mask_path)\n",
    "    mask = np.array(mask)\n",
    "    mask = mask[mask != 0]  # ignore background\n",
    "    if len(mask) == 0:\n",
    "        return 0\n",
    "    return int(np.bincount(mask.flatten()).argmax())\n",
    "\n",
    "# Data Loading\n",
    "X, y = [], []\n",
    "image_files = sorted(os.listdir(IMAGE_DIR))\n",
    "\n",
    "print(\" Loading tiles:\", end=\" \")\n",
    "for file in tqdm(image_files):\n",
    "    img_path = os.path.join(IMAGE_DIR, file)\n",
    "    mask_path = os.path.join(LABEL_DIR, file)\n",
    "\n",
    "    if os.path.exists(mask_path):\n",
    "        features = extract_features(img_path)\n",
    "        label = extract_label(mask_path)\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "\n",
    "print(f\"\\nâœ… Dataset shape: {np.array(X).shape}, Labels: {Counter(y)}\")\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# âœ… Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nâœ… Random Forest Accuracy: {accuracy:.4f}\\n\")\n",
    "print(\"ðŸ“Š Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119c1eb5-319f-4280-854b-acdb219cdf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn_classifier_task3.py\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tile folders\n",
    "IMAGE_DIR = \"data/tiles/images\"\n",
    "LABEL_DIR = \"data/tiles/labels\"\n",
    "\n",
    "# Parameters\n",
    "IMG_SIZE = 64  # resized down from 256x256\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "def load_data():\n",
    "    X, y = [], []\n",
    "\n",
    "    all_images = sorted(os.listdir(IMAGE_DIR))\n",
    "\n",
    "    for img_file in tqdm(all_images, desc=\" Loading tiles\"):\n",
    "        label_file = img_file.replace(\".png\", \".png\")\n",
    "        img_path = os.path.join(IMAGE_DIR, img_file)\n",
    "        label_path = os.path.join(LABEL_DIR, label_file)\n",
    "\n",
    "        if not os.path.exists(label_path):\n",
    "            continue\n",
    "\n",
    "        # Load and resize image & mask\n",
    "        img = np.array(Image.open(img_path).resize((IMG_SIZE, IMG_SIZE))) / 255.0\n",
    "        mask = np.array(Image.open(label_path).resize((IMG_SIZE, IMG_SIZE), resample=Image.NEAREST))\n",
    "\n",
    "        # Use the most common pixel value in the mask as the label\n",
    "        label = int(Counter(mask.flatten()).most_common(1)[0][0])\n",
    "\n",
    "        X.append(img)\n",
    "        y.append(label)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_data()\n",
    "print(f\"\\nâœ… Dataset shape: {X.shape}, Labels: {Counter(y)}\")\n",
    "\n",
    "# One-hot encode labels\n",
    "y_cat = to_categorical(y, NUM_CLASSES)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64)\n",
    "\n",
    "# Evaluate\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nâœ… CNN Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Predict class labels on test data\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Class ID to label mapping\n",
    "class_labels = {\n",
    "    0: \"Urban\",\n",
    "    1: \"Agriculture\",\n",
    "    2: \"Rangeland\",\n",
    "    3: \"Forest\",\n",
    "    4: \"Water\",\n",
    "    5: \"Barren\",\n",
    "    6: \"Unknown\"\n",
    "}\n",
    "\n",
    "# Visualize 5 random predictions\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(5):\n",
    "    idx = np.random.randint(0, len(X_test))\n",
    "    img = X_test[idx]\n",
    "\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Pred: {class_labels[y_pred[idx]]}\\nTrue: {class_labels[y_true[idx]]}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"cnn_landcover_model.h5\")\n",
    "print(\"ðŸ’¾ Model saved as cnn_landcover_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124cd121-dedb-49cf-b855-9ad0ae4954cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering_task4.py\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
    "from collections import Counter\n",
    "\n",
    "# Paths\n",
    "image_dir = \"data/tiles/images\"\n",
    "label_dir = \"data/tiles/labels\"\n",
    "\n",
    "def extract_features(image_path):\n",
    "    img = np.array(Image.open(image_path).convert(\"RGB\"))\n",
    "    return img.mean(axis=(0, 1))  # Mean R, G, B\n",
    "\n",
    "def extract_label(mask_path):\n",
    "    mask = np.array(Image.open(mask_path))\n",
    "    flat = mask.flatten()\n",
    "    flat = flat[flat > 0]\n",
    "    return int(np.bincount(flat).argmax()) if len(flat) > 0 else 0\n",
    "\n",
    "# Load data\n",
    "X, y_true = [], []\n",
    "image_files = sorted(os.listdir(image_dir))\n",
    "\n",
    "print(f\"ðŸ“¦ Found {len(image_files)} image tiles\")\n",
    "\n",
    "for file in tqdm(image_files, desc=\"ðŸ”„ Loading tiles\"):\n",
    "    img_path = os.path.join(image_dir, file)\n",
    "    mask_path = os.path.join(label_dir, file)\n",
    "    if os.path.exists(mask_path):\n",
    "        X.append(extract_features(img_path))\n",
    "        y_true.append(extract_label(mask_path))\n",
    "\n",
    "X = np.array(X)\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "print(\"âœ… Data loaded:\", X.shape)\n",
    "\n",
    "# KMeans clustering\n",
    "print(\"\\nðŸ” Running KMeans...\")\n",
    "kmeans = KMeans(n_clusters=7, random_state=42, n_init='auto')\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "\n",
    "ari_kmeans = adjusted_rand_score(y_true, y_kmeans)\n",
    "sil_kmeans = silhouette_score(X, y_kmeans)\n",
    "\n",
    "# DBSCAN clustering\n",
    "print(\"\\nðŸ” Running DBSCAN...\")\n",
    "dbscan = DBSCAN(eps=20, min_samples=5)\n",
    "y_dbscan = dbscan.fit_predict(X)\n",
    "\n",
    "ari_dbscan = adjusted_rand_score(y_true, y_dbscan)\n",
    "sil_dbscan = silhouette_score(X, y_dbscan)\n",
    "\n",
    "# Report results\n",
    "print(\"\\nðŸ“Š Clustering Evaluation Report:\")\n",
    "print(f\"KMeans - ARI: {ari_kmeans:.4f}, Silhouette Score: {sil_kmeans:.4f}\")\n",
    "print(f\"DBSCAN - ARI: {ari_dbscan:.4f}, Silhouette Score: {sil_dbscan:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5021b63-9522-43bd-bc59-b5c4ccf35892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load a mask file\n",
    "mask = np.array(Image.open(\"DeepGlobe/temp_converted/119_mask_class.png\"))\n",
    "\n",
    "# Define color map for 7 classes\n",
    "colors = [\n",
    "    (0, 255, 255),     # Urban\n",
    "    (255, 255, 0),     # Agriculture\n",
    "    (255, 0, 255),     # Rangeland\n",
    "    (0, 255, 0),       # Forest\n",
    "    (0, 0, 255),       # Water\n",
    "    (255, 255, 255),   # Barren\n",
    "    (0, 0, 0)          # Unknown\n",
    "]\n",
    "\n",
    "# Convert class mask to RGB image\n",
    "rgb_mask = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
    "for class_idx, color in enumerate(colors):\n",
    "    rgb_mask[mask == class_idx] = color\n",
    "\n",
    "plt.imshow(rgb_mask)\n",
    "plt.title(\"Visualized Class Mask\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2399a32b-1770-4619-96c6-b3abd1b381f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_preictions.py\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from collections import Counter\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# === Common Settings ===\n",
    "IMAGE_DIR = \"data/tiles/images\"\n",
    "LABEL_DIR = \"data/tiles/labels\"\n",
    "IMG_SIZE = 64\n",
    "NUM_CLASSES = 7\n",
    "CLASS_NAMES = [\"Urban\", \"Agriculture\", \"Rangeland\", \"Forest\", \"Water\", \"Barren\", \"Unknown\"]\n",
    "\n",
    "# === CNN Confusion Matrix ===\n",
    "print(\"\\nðŸ“¦ Running CNN confusion matrix evaluation...\")\n",
    "\n",
    "cnn_model = load_model(\"cnn_landcover_model.h5\")\n",
    "\n",
    "X_cnn, y_true_cnn = [], []\n",
    "files = sorted(os.listdir(IMAGE_DIR))\n",
    "\n",
    "for file in tqdm(files, desc=\"ðŸ”„ Loading tiles for CNN\"):\n",
    "    img_path = os.path.join(IMAGE_DIR, file)\n",
    "    label_path = os.path.join(LABEL_DIR, file)\n",
    "\n",
    "    if not os.path.exists(label_path):\n",
    "        continue\n",
    "\n",
    "    img = np.array(Image.open(img_path).resize((IMG_SIZE, IMG_SIZE))) / 255.0\n",
    "    mask = np.array(Image.open(label_path).resize((IMG_SIZE, IMG_SIZE), resample=Image.NEAREST))\n",
    "    label = int(Counter(mask.flatten()).most_common(1)[0][0])\n",
    "\n",
    "    X_cnn.append(img)\n",
    "    y_true_cnn.append(label)\n",
    "\n",
    "X_cnn = np.array(X_cnn)\n",
    "y_true_cnn = np.array(y_true_cnn)\n",
    "\n",
    "y_pred_cnn = np.argmax(cnn_model.predict(X_cnn, batch_size=64), axis=1)\n",
    "\n",
    "cm_cnn = confusion_matrix(y_true_cnn, y_pred_cnn, labels=range(NUM_CLASSES))\n",
    "disp_cnn = ConfusionMatrixDisplay(confusion_matrix=cm_cnn, display_labels=CLASS_NAMES)\n",
    "plt.figure(figsize=(10, 8))\n",
    "disp_cnn.plot(cmap=\"Blues\", xticks_rotation=45)\n",
    "plt.title(\"ðŸ“Š Confusion Matrix: CNN Land Cover Prediction\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === MLP Confusion Matrix ===\n",
    "print(\"\\nðŸ“¦ Running MLP confusion matrix evaluation...\")\n",
    "\n",
    "mlp_model = joblib.load(\"mlp_landcover_model.pkl\")\n",
    "\n",
    "def extract_mlp_features(image_path):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img = np.array(img)\n",
    "    return [img[:, :, 0].mean(), img[:, :, 1].mean(), img[:, :, 2].mean()]\n",
    "\n",
    "def extract_mlp_label(mask_path):\n",
    "    mask = np.array(Image.open(mask_path))\n",
    "    flat = mask.flatten()\n",
    "    flat = flat[flat > 0]\n",
    "    return int(np.bincount(flat).argmax()) if len(flat) > 0 else 0\n",
    "\n",
    "X_mlp, y_true_mlp = [], []\n",
    "for file in tqdm(files, desc=\"ðŸ”„ Loading tiles for MLP\"):\n",
    "    img_path = os.path.join(IMAGE_DIR, file)\n",
    "    mask_path = os.path.join(LABEL_DIR, file)\n",
    "\n",
    "    if os.path.exists(mask_path):\n",
    "        X_mlp.append(extract_mlp_features(img_path))\n",
    "        y_true_mlp.append(extract_mlp_label(mask_path))\n",
    "\n",
    "X_mlp = np.array(X_mlp)\n",
    "y_true_mlp = np.array(y_true_mlp)\n",
    "y_pred_mlp = mlp_model.predict(X_mlp)\n",
    "\n",
    "cm_mlp = confusion_matrix(y_true_mlp, y_pred_mlp, labels=range(NUM_CLASSES))\n",
    "disp_mlp = ConfusionMatrixDisplay(confusion_matrix=cm_mlp, display_labels=CLASS_NAMES)\n",
    "plt.figure(figsize=(10, 8))\n",
    "disp_mlp.plot(cmap=\"Purples\", xticks_rotation=45)\n",
    "plt.title(\"ðŸ“Š Confusion Matrix: MLP Land Cover Prediction\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ee73c5-d3c6-490c-aaaf-52f2ad6b9527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
